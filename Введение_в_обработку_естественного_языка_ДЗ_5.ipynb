{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Тема “POS-tagger и NER”\n",
        "\n",
        "## Задание 1. Написать теггер на данных с русским языком\n",
        "### 1.\tпроверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации\n"
      ],
      "metadata": {
        "id": "qabUuA9_H7XX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n",
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-b.conllu\n",
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-c.conllu\n",
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-test.conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdsSJzyVQ_gn",
        "outputId": "822d8c07-7205-4483-a4a3-a1a957be1ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-21 18:03:47--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40736565 (39M) [text/plain]\n",
            "Saving to: ‘ru_syntagrus-ud-train-a.conllu’\n",
            "\n",
            "ru_syntagrus-ud-tra 100%[===================>]  38.85M   196MB/s    in 0.2s    \n",
            "\n",
            "2022-10-21 18:03:48 (196 MB/s) - ‘ru_syntagrus-ud-train-a.conllu’ saved [40736565/40736565]\n",
            "\n",
            "--2022-10-21 18:03:48--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-b.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42819806 (41M) [text/plain]\n",
            "Saving to: ‘ru_syntagrus-ud-train-b.conllu’\n",
            "\n",
            "ru_syntagrus-ud-tra 100%[===================>]  40.84M   189MB/s    in 0.2s    \n",
            "\n",
            "2022-10-21 18:03:49 (189 MB/s) - ‘ru_syntagrus-ud-train-b.conllu’ saved [42819806/42819806]\n",
            "\n",
            "--2022-10-21 18:03:50--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-c.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32367464 (31M) [text/plain]\n",
            "Saving to: ‘ru_syntagrus-ud-train-c.conllu’\n",
            "\n",
            "ru_syntagrus-ud-tra 100%[===================>]  30.87M   172MB/s    in 0.2s    \n",
            "\n",
            "2022-10-21 18:03:50 (172 MB/s) - ‘ru_syntagrus-ud-train-c.conllu’ saved [32367464/32367464]\n",
            "\n",
            "--2022-10-21 18:03:50--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-test.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14970938 (14M) [text/plain]\n",
            "Saving to: ‘ru_syntagrus-ud-test.conllu’\n",
            "\n",
            "ru_syntagrus-ud-tes 100%[===================>]  14.28M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-10-21 18:03:51 (111 MB/s) - ‘ru_syntagrus-ud-test.conllu’ saved [14970938/14970938]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyconll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am9VV88PJ037",
        "outputId": "dd397cf2-1425-4e63-c608-c1d826e00d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyconll\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyconll\n",
            "Successfully installed pyconll-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bo9KlMc9HpiA"
      },
      "outputs": [],
      "source": [
        "import pyconll"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_train = pyconll.load_from_file('ru_syntagrus-ud-train-a.conllu')\n",
        "full_train_b = pyconll.load_from_file('ru_syntagrus-ud-train-b.conllu')\n",
        "full_train_c = pyconll.load_from_file('ru_syntagrus-ud-train-c.conllu')\n",
        "full_test = pyconll.load_from_file('ru_syntagrus-ud-test.conllu')\n",
        "\n",
        "full_train.extend([*full_train_b, *full_train_c])"
      ],
      "metadata": {
        "id": "rOjutvK-LdsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fdata_train = []\n",
        "for sent in full_train[:]:\n",
        "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
        "\n",
        "fdata_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
        "\n",
        "fdata_sent_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_sent_test.append([token.form for token in sent])\n",
        "#fdata_sent_test = fdata_sent_test[0]"
      ],
      "metadata": {
        "id": "RAA6l0UBaC6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import DefaultTagger\n",
        "from nltk.tag import UnigramTagger\n",
        "from nltk.tag import BigramTagger, TrigramTagger\n",
        "from nltk.tag import RegexpTagger\n",
        "from nltk.tag import SequentialBackoffTagger\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "MJSNfrbJhYNu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_tagger = DefaultTagger('NN')\n",
        "display(default_tagger.tag(fdata_sent_test), default_tagger.accuracy(fdata_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ujtCrN9YnfVs",
        "outputId": "dc6861f1-2872-4726-acb5-7b7945348ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('В', 'NN'),\n",
              " ('советский', 'NN'),\n",
              " ('период', 'NN'),\n",
              " ('времени', 'NN'),\n",
              " ('число', 'NN'),\n",
              " ('ИТ', 'NN'),\n",
              " ('-', 'NN'),\n",
              " ('специалистов', 'NN'),\n",
              " ('в', 'NN'),\n",
              " ('Армении', 'NN'),\n",
              " ('составляло', 'NN'),\n",
              " ('около', 'NN'),\n",
              " ('десяти', 'NN'),\n",
              " ('тысяч', 'NN'),\n",
              " ('.', 'NN')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_tagger = UnigramTagger(fdata_train)\n",
        "display(unigram_tagger.tag(fdata_sent_test), unigram_tagger.accuracy(fdata_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "q8D6bDP8notQ",
        "outputId": "5555201d-835a-4934-ada2-3209449eed31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('В', 'ADP'),\n",
              " ('советский', 'ADJ'),\n",
              " ('период', 'NOUN'),\n",
              " ('времени', 'NOUN'),\n",
              " ('число', 'NOUN'),\n",
              " ('ИТ', 'PROPN'),\n",
              " ('-', 'PUNCT'),\n",
              " ('специалистов', 'NOUN'),\n",
              " ('в', 'ADP'),\n",
              " ('Армении', 'PROPN'),\n",
              " ('составляло', 'VERB'),\n",
              " ('около', 'ADP'),\n",
              " ('десяти', 'NUM'),\n",
              " ('тысяч', 'NOUN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.8880238497616922"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_tagger = BigramTagger(fdata_train, backoff=unigram_tagger)\n",
        "display(bigram_tagger.tag(fdata_sent_test), bigram_tagger.accuracy(fdata_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "5dCx7maovPDo",
        "outputId": "c4ac06be-9243-4c47-940d-48ce5c468f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('В', 'ADP'),\n",
              " ('советский', 'ADJ'),\n",
              " ('период', 'NOUN'),\n",
              " ('времени', 'NOUN'),\n",
              " ('число', 'NOUN'),\n",
              " ('ИТ', 'PROPN'),\n",
              " ('-', 'PUNCT'),\n",
              " ('специалистов', 'NOUN'),\n",
              " ('в', 'ADP'),\n",
              " ('Армении', 'PROPN'),\n",
              " ('составляло', 'VERB'),\n",
              " ('около', 'ADP'),\n",
              " ('десяти', 'NUM'),\n",
              " ('тысяч', 'NOUN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.89297989100507"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_tagger = TrigramTagger(fdata_train, backoff=bigram_tagger)\n",
        "display(trigram_tagger.tag(fdata_sent_test), trigram_tagger.accuracy(fdata_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "DG0d5sJnwW56",
        "outputId": "f9871c57-3510-4d9a-a1a4-2d5da38af617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('В', 'ADP'),\n",
              " ('советский', 'ADJ'),\n",
              " ('период', 'NOUN'),\n",
              " ('времени', 'NOUN'),\n",
              " ('число', 'NOUN'),\n",
              " ('ИТ', 'NOUN'),\n",
              " ('-', 'PUNCT'),\n",
              " ('специалистов', 'NOUN'),\n",
              " ('в', 'ADP'),\n",
              " ('Армении', 'PROPN'),\n",
              " ('составляло', 'VERB'),\n",
              " ('около', 'ADP'),\n",
              " ('десяти', 'NUM'),\n",
              " ('тысяч', 'NOUN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.8918848780611308"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
        "    for cls in tagger_classes:\n",
        "        backoff = cls(train_sents, backoff=backoff)\n",
        "    return backoff\n",
        "\n",
        "\n",
        "backoff = DefaultTagger('NN') \n",
        "tag = backoff_tagger(fdata_train,  \n",
        "                     [UnigramTagger, BigramTagger, TrigramTagger],  \n",
        "                     backoff = backoff) \n",
        "  \n",
        "tag.accuracy(fdata_test) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJobKuF8wnd1",
        "outputId": "aa1213a3-900e-4320-931c-d049f3acf493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8914861161220085"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.\tнаписать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов"
      ],
      "metadata": {
        "id": "RvPkcglkxV1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NamesTagger(SequentialBackoffTagger):\n",
        "    def __init__(self, model, *args, **kwargs):\n",
        "        SequentialBackoffTagger.__init__(self, *args, **kwargs)\n",
        "        self.model = model\n",
        "            \n",
        "    def choose_tag(self, tokens, index, history):\n",
        "        word = tokens[index]\n",
        "        return self.model.tag([word])[0][1]\n",
        "            \n",
        "nt = NamesTagger(trigram_tagger)\n",
        "print(nt.tag(['составляло', 'период'])) \n",
        "print(nt.tag(['Армении'])) \n",
        "print(nt.tag(['.']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc7Ht3pUxY2U",
        "outputId": "80f54496-10da-4bd6-c7d5-a69f5c0ef479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('составляло', 'VERB'), ('период', 'NOUN')]\n",
            "[('Армении', 'PROPN')]\n",
            "[('.', 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nt.accuracy(fdata_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-6A2P2U4wzD",
        "outputId": "724b635c-c14a-41ee-9fae-8c0dd8b03827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8845995607289115"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.\tсравнить все реализованные методы сделать выводы:\n",
        "- Все используемые методы показали не плохие результаты, и этого результата мы смогли добиться по причине очень качественных исходных данных. "
      ],
      "metadata": {
        "id": "-fqgLNHxxZIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2. Проверить насколько хорошо работает NER данные брать из http://www.labinform.ru/pub/named_entities/\n",
        "### 1.\tпроверить NER из nltk/spacy/deeppavlov.\n",
        "### 2.\tнаписать свой NER, попробовать разные подходы.\n",
        "\n",
        "a.\tпередаём в сетку токен и его соседей.\n",
        "\n",
        "b.\tпередаём в сетку только токен.\n",
        "            \n",
        "c.\tсвой вариант.\n",
        "\n",
        "#### 3.\tсравнить свои реализованные подходы на качество — вывести precision/recall/f1_score.\n"
      ],
      "metadata": {
        "id": "dHSmLtoUIllY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwgKcQeOCjKX",
        "outputId": "4546670a-f13a-4efa-adec-658650d4fa04"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def url_to_string(url):\n",
        "    res = requests.get(url)\n",
        "    #html = res.text\n",
        "    soup = BeautifulSoup(res.content, 'html.parser')\n",
        "    for script in soup([\"script\", \"style\", 'aside']):\n",
        "        script.extract()\n",
        "    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))"
      ],
      "metadata": {
        "id": "L3FuH1Op9xDB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = url_to_string('http://www.labinform.ru/pub/named_entities/')"
      ],
      "metadata": {
        "id": "uRmCPzz6Co2u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***nltk***"
      ],
      "metadata": {
        "id": "TCZlqHl-Cs1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag(nltk.word_tokenize(document))[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epn74yomAsQz",
        "outputId": "27245ca9-150d-4473-9ffc-a58f1c91857c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Размеченные', 'JJ'),\n",
              " ('коллекции', 'NNP'),\n",
              " ('для', 'NNP'),\n",
              " ('извлечения', 'NNP'),\n",
              " ('именованных', 'NNP'),\n",
              " ('сущностей', 'NNP'),\n",
              " ('LABINFORM.RU', 'NNP'),\n",
              " ('РАЗМЕЧЕННЫЕ', 'NNP'),\n",
              " ('КОЛЛЕКЦИИ', 'NNP'),\n",
              " ('ДЛЯ', 'NNP'),\n",
              " ('ИЗВЛЕЧЕНИЯ', 'NNP'),\n",
              " ('ИМЕНОВАННЫХ', 'NNP'),\n",
              " ('СУЩНОСТЕЙ', 'NNP'),\n",
              " ('Коллекция', 'NNP'),\n",
              " ('Named_Entities_5', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(document))) if hasattr(chunk, 'label') }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcsGbqeTCD9T",
        "outputId": "1e10b966-7a6a-4e17-9dac-482b5fe720ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('DOI', 'ORGANIZATION'),\n",
              " ('Geopolit', 'ORGANIZATION'),\n",
              " ('ISMW', 'ORGANIZATION'),\n",
              " ('Intelligence', 'GPE'),\n",
              " ('Loc', 'ORGANIZATION'),\n",
              " ('Loc Имена', 'PERSON'),\n",
              " ('Loukachevitch N.', 'PERSON'),\n",
              " ('MEDIA', 'ORGANIZATION'),\n",
              " ('Org', 'ORGANIZATION'),\n",
              " ('Org Москвы', 'PERSON'),\n",
              " ('Org Правительства', 'PERSON'),\n",
              " ('Org Разметка', 'PERSON'),\n",
              " ('PDF', 'ORGANIZATION'),\n",
              " ('Russian', 'GPE'),\n",
              " ('Social Media', 'ORGANIZATION'),\n",
              " ('Библиотека', 'ORGANIZATION'),\n",
              " ('Вложенные', 'PERSON'),\n",
              " ('Коллекция', 'PERSON'),\n",
              " ('Ленина', 'PERSON'),\n",
              " ('Лукашевич', 'PERSON'),\n",
              " ('Можарова В.А.', 'PERSON'),\n",
              " ('Москва', 'PERSON'),\n",
              " ('Типы', 'PERSON'),\n",
              " ('сущностейКоличество Pers10623', 'ORGANIZATION')}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***spacy***"
      ],
      "metadata": {
        "id": "zuXL4bRJSKQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSIkCULYSj7i",
        "outputId": "dff4281c-7778-469b-97c2-18a1ca57b0cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.1\n",
            "    Uninstalling spacy-3.4.1:\n",
            "      Successfully uninstalled spacy-3.4.1\n",
            "Successfully installed spacy-3.4.2\n",
            "2022-10-22 10:43:37.995357: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[1m\n",
            "============================== Info about spaCy ==============================\u001b[0m\n",
            "\n",
            "spaCy version    3.4.2                         \n",
            "Location         /usr/local/lib/python3.7/dist-packages/spacy\n",
            "Platform         Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Python version   3.7.15                        \n",
            "Pipelines        en_core_web_sm (3.4.1)        \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import en_core_web_sm\n",
        "\n",
        "nlp = en_core_web_sm.load()\n",
        "article = nlp(document)\n",
        "displacy.render(article, jupyter=True, style='ent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "qbznmHZuSJ3j",
        "outputId": "9d8fa3b5-f165-4edd-9946-e462b82d6a64"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> Размеченные коллекции для извлечения именованных сущностей \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    LABINFORM.RU\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " \r РАЗМЕЧЕННЫЕ КОЛЛЕКЦИИ ДЛЯ ИЗВЛЕЧЕНИЯ \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ИМЕНОВАННЫХ СУЩНОСТЕЙ\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "\r  Коллекция Named_Entities_5 \r \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Размеченная\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " коллекция Named_Entities_5 создана для оценки \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    качества\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " алгоритмов автоматического извлечения именованных сущностей \r из текстов на русском языке. \r В качестве основы для разметки \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    этих коллекций\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " взята коллекция \r Persons-1000, \r подготовленная \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Исследовательским\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " центром \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Искусственного\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " интеллекта \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Института\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " программных систем \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    РАН\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              ". \r \r В коллекции \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Persons-1000\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " были размечены упоминания имен персон в текстах, \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    а также было приведено каноническое\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " названия упомянутых персон. Особенностью этой разметки было то, что размечались только собственные имена персон, в \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    разметку не включались\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    в частностью\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    упоминания ролей персон\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " (президент, отец) \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    считаются\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " реляционным типом информации.\r \r В коллекции Named_Entities_5 разметка имен людей из коллекции \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Persons-1000\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " была дополнена следующими типами имен:\r организации (Org)\r источники информации - средства массовой информации, организации, имеющие функцию информирования (MEDIA)\r места (Loc)\r \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    государства\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " (Geopolit),  страны и столицы, выступающие в роли правительства (например, «\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Москва\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " анонсировала») \r \r Особенностью новой разметки является то, что в \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    подавляющем числе\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " случаев размеченное имя должно начинаться с заглавной буквы. Важными принципами разметки являются следующие:\r \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    в разметке нет вложенных именованных\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " сущностей, \r именованные \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    сущности не могут пересекаться\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ",\r каждому \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    токену соответствует не более одного\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    класса разметки\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ".\r \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Конкретные\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " случаи\r   Имя внутри названия организации не размечается отдельно:\r [\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Библиотека\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " имени \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    В.И. Ленина\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "] - org  \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Вложенные\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " организации и место, к которому \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    они относятся\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " размечаются отдельно. \r Это упрощенный подход к \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    разметке\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    организаций\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", но он позволяет делать разметку с высокой степенью согласия между разметчиками\r \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Общественный\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " совет \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Правительства Москвы\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " [\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Общественный\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " совет] - Org Правительства - Org Москвы -  Loc  Имена мест, людей, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    организаций в кавычках\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " размечаются \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    в соответствии с\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " тем, что значит это имя в кавычках:\r Гостиница &quot;Москва&quot; - Org \r Разметка производилась одним экспертом с помощью инструмента \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brat\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ". \r Затем на \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    этой разметке\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " была обучена система извлечения именованных сущностей с использованием кросс-валидации. \r Автоматическая разметка тестовой \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    части\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " сравнивалась с ручной \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    разметкой\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " и выявлялись случаи, когда система разметила правильно, \r а эксперт ошибся (пропустил, спутал \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    тип сущности\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", неточно установил границы сущности). \r В случае обнаружения \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    неточности экспертной разметки\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", в разметку вносилась правка.\r   \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Число\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " размеченных объектов в коллекции:   Типы сущностейКоличество  Pers10623  Org 7032  Media \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1509\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "  Loc 3141  Geopolit 4103  Коллекция Named_Entities_3  \r Также сделан вариант разметки именованных сущностей по трем классам Named_Entities_3: \r имена людей, имена \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    организаций\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ",  географические названия,  \r в которой названия государств присоединены к локациям, а имена медиа-\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    организаций\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " - к организациям.\r Скачать коллекции  Named_Entities_5   Named_Entities_3  Для библиографических ссылок  \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mozharova V.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Loukachevitch N.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              "-stage approach in \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Russian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " named entity recognition \r // International FRUCT Conference on Intelligence, Social Media and Web, ISMW FRUCT 2016. \r \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Saint-Petersburg\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "; \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Russian Federation\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", DOI 10.1109/FRUCT.2016.7584769 \r (\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    PDF\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ")  \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Можарова В.А.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", Лукашевич Н.В. Двухэтапный подход к извлечению именованных сущностей \r // Труды конференции по \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    искусственному\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " интеллекту КИИ-2016, т.2., \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2016\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". - С.81-88.\r (\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    PDF\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ") Благодарности Коллекция создана при поддержке РФФИ (проект № \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    15\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              "-07-09306)\r </div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Deeppavlov***"
      ],
      "metadata": {
        "id": "lCXmQLmwVF5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install deeppavlov\n",
        "! python -m deeppavlov install ner_rus\n",
        "! python -m deeppavlov interact -d ner_rus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VJ1cGVoGuhd8",
        "outputId": "e9b2c6bc-954a-4d64-ae77-6aef382d1a7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deeppavlov\n",
            "  Downloading deeppavlov-0.17.6-py3-none-any.whl (878 kB)\n",
            "\u001b[K     |████████████████████████████████| 878 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "  Downloading scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 20.2 MB/s \n",
            "\u001b[?25hCollecting prometheus-client==0.7.1\n",
            "  Downloading prometheus_client-0.7.1.tar.gz (38 kB)\n",
            "Collecting pymorphy2==0.8\n",
            "  Downloading pymorphy2-0.8-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "  Downloading pyTelegramBotAPI-3.6.7.tar.gz (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.17.3)\n",
            "Collecting fastapi==0.47.1\n",
            "  Downloading fastapi-0.47.1-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 42.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
            "\u001b[K     |████████████████████████████████| 859 kB 64.0 MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "  Downloading pytz-2019.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 52.2 MB/s \n",
            "\u001b[?25hCollecting pyopenssl==22.0.0\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Collecting pydantic==1.3\n",
            "  Downloading pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 30.4 MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts-ru\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 26.6 MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading rusenttokenize-0.0.5-py3-none-any.whl (10 kB)\n",
            "Collecting aio-pika==6.4.1\n",
            "  Downloading aio_pika-6.4.1-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 19 kB/s \n",
            "\u001b[?25hCollecting uvloop==0.14.0\n",
            "  Downloading uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 40.1 MB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading overrides-2.7.0.tar.gz (4.5 kB)\n",
            "Collecting ruamel.yaml==0.15.100\n",
            "  Downloading ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654 kB)\n",
            "\u001b[K     |████████████████████████████████| 654 kB 55.5 MB/s \n",
            "\u001b[?25hCollecting filelock==3.0.12\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting pandas==0.25.3\n",
            "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 22.4 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.62.0\n",
            "  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "  Downloading Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 46.6 MB/s \n",
            "\u001b[?25hCollecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 42.0 MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "  Downloading numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 55.0 MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.11.7\n",
            "  Downloading uvicorn-0.11.7-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading aiormq-3.3.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: yarl in /usr/local/lib/python3.7/dist-packages (from aio-pika==6.4.1->deeppavlov) (1.8.1)\n",
            "Collecting starlette<=0.12.9,>=0.12.9\n",
            "  Downloading starlette-0.12.9.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 60.1 MB/s \n",
            "\u001b[?25hCollecting docopt>=0.6\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Collecting cryptography>=35.0\n",
            "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 50.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2022.9.24)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Collecting idna<2.9,>=2.5\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.2.0)\n",
            "Collecting httptools==0.1.*\n",
            "  Downloading httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219 kB)\n",
            "\u001b[K     |████████████████████████████████| 219 kB 41.7 MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.8 MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading pamqp-2.3.0-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=35.0->pyopenssl==22.0.0->deeppavlov) (2.21)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (4.1.1)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (6.0.2)\n",
            "Building wheels for collected packages: nltk, overrides, prometheus-client, pytelegrambotapi, sacremoses, docopt, starlette\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449924 sha256=296eebe07e8abcb7b85d4230ca290be7756905a02d9d1b7a47b039f98722f15f\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-py3-none-any.whl size=5603 sha256=cb3b5b91e36c38d060b99522b494d7fe82002b059975454596d2d59fb82d00c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/87/45/bfdacf6c3b8233b6e8d519edcbd1cf297ad5ff5f0bf84bb9c1\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-py3-none-any.whl size=41405 sha256=72c200e4b1a8d74e25aaea8bf28919d45887a8e6b27c9f514e8a3fa95cb392b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/0c/26/59ba285bf65dc79d195e9b25e2ddde4c61070422729b0cd914\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-py3-none-any.whl size=47176 sha256=b7490e074b2cb7eb10b5d60d30b9e426391b53cd8caefd50fc185d90b36ec952\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/7c/54/8eddf2369ef1b9190e2ee6dc2b40df54b6c65529a38790fdd4\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=4fe63d92255397226afec6e348ef0459d3143a8869371756176710519dd642a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=f00d6808238e36ecf0e93020d12391a8590497a0ee9733d2fb0bb6b218f4a9c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-py3-none-any.whl size=57252 sha256=01983682648f9ae8fb5dc8aece7cfd699dc531bae06f71241208d21027686a55\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/78/be/f57ed5aed7cd222abdb24e3186b5c9f1074184fcc0a295102b\n",
            "Successfully built nltk overrides prometheus-client pytelegrambotapi sacremoses docopt starlette\n",
            "Installing collected packages: idna, pamqp, numpy, websockets, uvloop, tqdm, starlette, scipy, requests, pytz, pymorphy2-dicts, pydantic, httptools, h11, docopt, dawg-python, cryptography, aiormq, uvicorn, scikit-learn, sacremoses, rusenttokenize, ruamel.yaml, pytelegrambotapi, pyopenssl, pymorphy2-dicts-ru, pymorphy2, prometheus-client, pandas, overrides, nltk, h5py, filelock, fastapi, Cython, aio-pika, deeppavlov\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.1\n",
            "    Uninstalling tqdm-4.64.1:\n",
            "      Successfully uninstalled tqdm-4.64.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.4\n",
            "    Uninstalling pytz-2022.4:\n",
            "      Successfully uninstalled pytz-2022.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.9.2\n",
            "    Uninstalling pydantic-1.9.2:\n",
            "      Successfully uninstalled pydantic-1.9.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.8.0\n",
            "    Uninstalling filelock-3.8.0:\n",
            "      Successfully uninstalled filelock-3.8.0\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 0.29.32\n",
            "    Uninstalling Cython-0.29.32:\n",
            "      Successfully uninstalled Cython-0.29.32\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "xarray 0.20.2 requires pandas>=1.1, but you have pandas 0.25.3 which is incompatible.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.18.0 which is incompatible.\n",
            "thinc 8.1.4 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
            "tensorflow 2.9.2 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n",
            "spacy 3.4.1 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
            "prophet 1.1.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.18.0 which is incompatible.\n",
            "plotnine 0.8.0 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "mizani 0.7.3 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.23 requires numpy>=1.20, but you have numpy 1.18.0 which is incompatible.\n",
            "jax 0.3.23 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests>=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "confection 0.0.3 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 1.3 which is incompatible.\n",
            "cmdstanpy 1.0.7 requires numpy>=1.21, but you have numpy 1.18.0 which is incompatible.\n",
            "aeppl 0.0.33 requires numpy>=1.18.1, but you have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-38.0.1 dawg-python-0.7.2 deeppavlov-0.17.6 docopt-0.6.2 fastapi-0.47.1 filelock-3.0.12 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-22.0.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 scipy-1.4.1 starlette-0.12.9 tqdm-4.62.0 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "nltk",
                  "numpy",
                  "requests",
                  "scipy",
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deeppavlov\n",
        "from deeppavlov import configs, build_model\n",
        "deeppavlov_ner = build_model(configs.ner.ner_rus, download=False)\n",
        "deeppavlov_ner([document])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rouQRAIRC5u0",
        "outputId": "d5b03fc0-826d-48da-8c7e-750bb99574c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
            "2022-10-22 12:51:02.768 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_rus/word.dict]\n",
            "INFO:deeppavlov.core.data.simple_vocab:[loading vocabulary from /root/.deeppavlov/models/ner_rus/word.dict]\n",
            "2022-10-22 12:51:02.905 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_rus/tag.dict]\n",
            "INFO:deeppavlov.core.data.simple_vocab:[loading vocabulary from /root/.deeppavlov/models/ner_rus/tag.dict]\n",
            "2022-10-22 12:51:02.929 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_rus/char.dict]\n",
            "INFO:deeppavlov.core.data.simple_vocab:[loading vocabulary from /root/.deeppavlov/models/ner_rus/char.dict]\n",
            "2022-10-22 12:51:02.958 INFO in 'deeppavlov.models.embedders.fasttext_embedder'['fasttext_embedder'] at line 53: [loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/lenta_lower_100.bin`]\n",
            "INFO:deeppavlov.models.embedders.fasttext_embedder:[loading fastText embeddings from `/root/.deeppavlov/downloads/embeddings/lenta_lower_100.bin`]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/ner/network.py:96: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/ner/network.py:170: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py:409: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py:420: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/ner/network.py:211: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/common/check_gpu.py:29: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2022-10-22 12:51:07.869 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 760: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "INFO:deeppavlov.core.layers.tf_layers:\n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n",
            "2022-10-22 12:51:08.12 ERROR in 'deeppavlov.core.common.params'['params'] at line 112: Exception in <class 'deeppavlov.models.ner.network.NerNetwork'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/common/params.py\", line 106, in from_params\n",
            "    component = obj(**dict(config_params, **kwargs))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\", line 76, in __call__\n",
            "    obj.__init__(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\", line 28, in _wrapped\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/models/ner/network.py\", line 148, in __init__\n",
            "    units = self._build_cudnn_rnn(features, n_hidden_list, cell_type, intra_layer_dropout, self.mask_ph)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\", line 28, in _wrapped\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/models/ner/network.py\", line 215, in _build_cudnn_rnn\n",
            "    units, _ = cudnn_bi_lstm(units, n_hidden, sequence_lengths)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py\", line 862, in cudnn_bi_lstm\n",
            "    seq_lengths=seq_lengths)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py\", line 767, in cudnn_lstm_wrapper\n",
            "    seq_lengths, initial_h, initial_c, name, reuse)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py\", line 725, in cudnn_compatible_lstm\n",
            "    init_h = init_c = tf.zeros([n_layers, tf.shape(units)[0], n_hidden])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 2338, in zeros\n",
            "    output = _constant_if_small(zero, shape, dtype, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 2295, in _constant_if_small\n",
            "    if np.prod(shape) < 1000:\n",
            "  File \"<__array_function__ internals>\", line 6, in prod\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\", line 3052, in prod\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n",
            "    return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 736, in __array__\n",
            "    \" array.\".format(self.name))\n",
            "NotImplementedError: Cannot convert a symbolic Tensor (LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/strided_slice:0) to a numpy array.\n",
            "ERROR:deeppavlov.core.common.params:Exception in <class 'deeppavlov.models.ner.network.NerNetwork'>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/common/params.py\", line 106, in from_params\n",
            "    component = obj(**dict(config_params, **kwargs))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\", line 76, in __call__\n",
            "    obj.__init__(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\", line 28, in _wrapped\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/models/ner/network.py\", line 148, in __init__\n",
            "    units = self._build_cudnn_rnn(features, n_hidden_list, cell_type, intra_layer_dropout, self.mask_ph)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\", line 28, in _wrapped\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/models/ner/network.py\", line 215, in _build_cudnn_rnn\n",
            "    units, _ = cudnn_bi_lstm(units, n_hidden, sequence_lengths)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py\", line 862, in cudnn_bi_lstm\n",
            "    seq_lengths=seq_lengths)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py\", line 767, in cudnn_lstm_wrapper\n",
            "    seq_lengths, initial_h, initial_c, name, reuse)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py\", line 725, in cudnn_compatible_lstm\n",
            "    init_h = init_c = tf.zeros([n_layers, tf.shape(units)[0], n_hidden])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 2338, in zeros\n",
            "    output = _constant_if_small(zero, shape, dtype, name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 2295, in _constant_if_small\n",
            "    if np.prod(shape) < 1000:\n",
            "  File \"<__array_function__ internals>\", line 6, in prod\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\", line 3052, in prod\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n",
            "    return reduction(axis=axis, dtype=dtype, out=out, **passkwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\", line 736, in __array__\n",
            "    \" array.\".format(self.name))\n",
            "NotImplementedError: Cannot convert a symbolic Tensor (LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/strided_slice:0) to a numpy array.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-11ab342deaf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeeppavlov\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeeppavlov\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdeeppavlov_ner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner_rus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdeeppavlov_ner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/commands/infer.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(config, mode, load_trained, download, serialized)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mcomponent_serialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponent_serialized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'id'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomponent_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/common/params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[0;34m(params, mode, serialized, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0m_refs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0mwrapped_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_graph_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapped_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/models/ner/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_tags, token_emb_dim, char_emb_dim, capitalization_dim, pos_features_dim, additional_features, net_type, cell_type, use_cudnn_rnn, two_dense_on_top, n_hidden_list, cnn_filter_width, use_crf, token_emb_mat, char_emb_mat, use_batch_norm, dropout_keep_prob, embeddings_dropout, top_dropout, intra_layer_dropout, l2_reg, gpu, seed, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0ml2_reg\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuDNN RNN are not l2 regularizable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_cudnn_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintra_layer_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_ph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintra_layer_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_ph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_backend.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/models/ner/network.py\u001b[0m in \u001b[0;36m_build_cudnn_rnn\u001b[0;34m(self, units, n_hidden_list, cell_type, intra_layer_dropout, mask)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcell_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                     \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn_bi_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mcell_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gru'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn_bi_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py\u001b[0m in \u001b[0;36mcudnn_bi_lstm\u001b[0;34m(units, n_hidden, seq_lengths, n_layers, trainable_initial_states, name, reuse)\u001b[0m\n\u001b[1;32m    860\u001b[0m                                                               \u001b[0mn_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                                                               \u001b[0mtrainable_initial_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable_initial_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m                                                               seq_lengths=seq_lengths)\n\u001b[0m\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py\u001b[0m in \u001b[0;36mcudnn_lstm_wrapper\u001b[0;34m(units, n_hidden, n_layers, trainable_initial_states, seq_lengths, initial_h, initial_c, name, reuse)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     return cudnn_compatible_lstm(units, n_hidden, n_layers, trainable_initial_states,\n\u001b[0;32m--> 767\u001b[0;31m                                  seq_lengths, initial_h, initial_c, name, reuse)\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deeppavlov/core/layers/tf_layers.py\u001b[0m in \u001b[0;36mcudnn_compatible_lstm\u001b[0;34m(units, n_hidden, n_layers, trainable_initial_states, seq_lengths, initial_h, initial_c, name, reuse)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0minit_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0minit_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0minitial_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_h\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minit_h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2336\u001b[0m         \u001b[0;31m# Create a constant if it won't be very big. Otherwise create a fill op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2337\u001b[0m         \u001b[0;31m# to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2338\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[0;34m(value, shape, dtype, name)\u001b[0m\n\u001b[1;32m   2293\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2295\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2296\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \u001b[0mnumber_of_dimensions\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3051\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ma\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mScalars\u001b[0m \u001b[0mare\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3052\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3053\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0mAlso\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# support a dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\n\u001b[0;32m--> 736\u001b[0;31m                               \" array.\".format(self.name))\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (LSTM_0/cudnn_bi_gru/Forward/cudnn_lstm/strided_slice:0) to a numpy array."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "так и не победил в Colab разницу версий TensorFlow"
      ],
      "metadata": {
        "id": "3497tjcoxCtZ"
      }
    }
  ]
}